
# ğŸ¡ Median House Price Prediction - California Housing Dataset

## ğŸ“Œ Project Overview
Predicting median house prices using the **California Housing Dataset** by applying various machine learning models and selecting the best one.

## ğŸ“Š Dataset
- Contains housing information from California
- **Rows:** 20,640
- **Features:**
  - Longitude ğŸ“
  - Latitude ğŸŒ
  - Housing Median Age ğŸ 
  - Total Rooms ğŸ§
  - Total Bedrooms ğŸ¦
  - Population ğŸ‘¥
  - Households ğŸ¡
  - Median Income ğŸ’°
  - **Target:** Median House Value ğŸ’²

## ğŸ”„ Project Workflow
### 1ï¸âƒ£ Data Collection & Preprocessing
âœ” Load dataset ğŸ‘…  
âœ” Handle missing values ğŸš€  
âœ” Feature scaling & engineering ğŸ› ï¸  
âœ” Split data into train & test sets (80% train, 20% test) âœ‚ï¸  
âœ” Data Cleaning ğŸª‘  
âœ” Handling Text & Categorical Attributes ğŸŒ¤ï¸  
âœ” Feature Scaling âš–ï¸  
âœ” Created custom transformers:
   - **Log Transformer** ğŸ“ˆ
   - **RBF Transformer** ğŸŒ
   - **Ratio Transformer** â—
âœ” Implemented **Transformer Pipelines** ğŸ”„

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)
âœ” Visualize feature distributions ğŸ“Š  
âœ” Visualize data geographically to gain insights ğŸ—ºï¸  
âœ” Identify correlations ğŸ”—  
âœ” Experiment with attribute combinations âš—ï¸  
âœ” Detect & handle outliers âš ï¸  

### 3ï¸âƒ£ Model Selection & Training
âœ” Train multiple models:
   - **Linear Regression** ğŸ“‰
   - **Decision Trees** ğŸŒ³
   - **Random Forest** ğŸŒ²ğŸŒ²ğŸŒ²
âœ” Evaluate initial performance ğŸ¯

### 4ï¸âƒ£ Training and Evaluating on Training Set
âœ” **Linear Regression:** RMSE = **68,647.95** ğŸ“‰  
âœ” **Decision Tree Regressor:** RMSE = **0** (Overfitting) âš ï¸  
âœ” **Random Forest Regressor:** RMSE = **17,521.56** âœ…  

### 5ï¸âƒ£ Hyperparameter Tuning
âœ” **Grid Search:** Tuned number of clusters & max features sizes ğŸ¯
   - RMSE ranged between **43,000 - 44,000**
âœ” **Randomized Search:** Tried random combinations of hyperparameters ğŸ‰
   - RMSE ranged between **42,000 - 43,100**
âœ” Evaluated best models ğŸ†

### 6ï¸âƒ£ Model Evaluation
âœ” Evaluated system on the **Test Set** âœ…  
âœ” **Final RMSE on Test Set:** **41,556.05** ğŸ“Š  
âœ” Metrics used:
    
   - **Root Mean Squared Error (RMSE) ğŸ”¢**
  
âœ” **Best Model: Random Forest ğŸ¯**

## ğŸ“ˆ Results
| Model              | RMSE      |
|-------------------|----------|
| Linear Regression | 68,647.95 |
| Decision Tree    | 0 (Overfit) |
| Random Forest    | 17,521.56 |
| **Best Tuned Model** | **41,556.05** |

âœ… **Random Forest performed best!** ğŸš€

## ğŸ“ Key Learnings
- Visualizing data geographically provided valuable insights ğŸŒ
- Correlation analysis helped in feature selection ğŸ”—
- Experimenting with attribute combinations improved prediction accuracy âš—ï¸
- Scaling & feature engineering improved results âš™ï¸
- Custom transformers & pipelines enhanced preprocessing ğŸ”„
- Decision Trees overfit, Random Forest generalizes better ğŸ”
- Hyperparameter tuning boosted performance ğŸš€

## ğŸ”® Future Improvements
- Try advanced models like **XGBoost** ğŸ”¥
- Improve feature selection ğŸ¯
- Deploy using **Streamlit** or **Flask** ğŸ–¥ï¸

## ğŸ›‚ Dependencies
- Python 3.8+
- Pandas ğŸ¼
- NumPy ğŸ”¢
- Scikit-learn ğŸ¤–
- Matplotlib ğŸ“Š
- Seaborn ğŸ¨

## âœï¸ Author
Laxman Kumar Busetty
